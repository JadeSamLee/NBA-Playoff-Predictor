{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Web Scraping and Data Preparation"
      ],
      "metadata": {
        "id": "CM-dOLDrghrz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4p91sZargdGP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from urllib.request import urlopen\n",
        "from bs4 import BeautifulSoup\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def scrape_NBA_team_data(years=[2017, 2018]):\n",
        "    final_df = pd.DataFrame(columns=[\"Year\", \"Team\", \"W\", \"L\",\n",
        "                                      \"W/L%\", \"GB\", \"PS/G\", \"PA/G\",\n",
        "                                      \"SRS\", \"Playoffs\", \"Losing_season\"])\n",
        "\n",
        "    for y in years:\n",
        "        url = f\"https://www.basketball-reference.com/leagues/NBA_{y}_standings.html\"\n",
        "        html = urlopen(url)\n",
        "        soup = BeautifulSoup(html, \"lxml\")\n",
        "\n",
        "        titles = [th.getText() for th in soup.findAll('tr', limit=2)[0].findAll('th')]\n",
        "        headers = titles[1:titles.index(\"SRS\")+1]\n",
        "        titles = titles[titles.index(\"SRS\")+1:]\n",
        "\n",
        "        try:\n",
        "            row_titles = titles[0:titles.index(\"Eastern Conference\")]\n",
        "        except:\n",
        "            row_titles = titles\n",
        "        for i in headers:\n",
        "            if i in row_titles:\n",
        "                row_titles.remove(i)\n",
        "        row_titles = [x for x in row_titles if x not in\n",
        "                      [\"Eastern Conference\", \"Western Conference\"] +\n",
        "                      [\"Atlantic Division\", \"Central Division\", \"Southeast Division\",\n",
        "                       \"Northwest Division\", \"Pacific Division\", \"Southwest Division\",\n",
        "                       \"Midwest Division\"]]\n",
        "\n",
        "        rows = soup.findAll('tr')[1:]\n",
        "        team_stats = [[td.getText() for td in rows[i].findAll('td')] for i in range(len(rows))]\n",
        "        team_stats = [e for e in team_stats if e != []]\n",
        "        team_stats = team_stats[0:len(row_titles)]\n",
        "\n",
        "        for i in range(len(team_stats)):\n",
        "            team_stats[i].insert(0, row_titles[i])\n",
        "            team_stats[i].insert(0, y)\n",
        "\n",
        "        headers.insert(0, \"Team\")\n",
        "        headers.insert(0, \"Year\")\n",
        "\n",
        "        year_standings = pd.DataFrame(team_stats, columns=headers)\n",
        "        year_standings[\"Playoffs\"] = [\"Y\" if \"*\" in ele else \"N\" for ele in year_standings[\"Team\"]]\n",
        "        year_standings[\"Team\"] = [ele.replace('*', '') for ele in year_standings[\"Team\"]]\n",
        "        year_standings[\"Losing_season\"] = [\"Y\" if float(ele) < .5 else \"N\" for ele in year_standings[\"W/L%\"]]\n",
        "\n",
        "        final_df = pd.concat([final_df, year_standings], ignore_index=True)\n",
        "\n",
        "    final_df.reset_index(drop=True, inplace=True)\n",
        "    final_df.to_csv(\"nba_team_data.csv\", index=False)\n",
        "    return final_df\n"
      ],
      "metadata": {
        "id": "3lWqemszgk5J"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Execute the scraping function\n",
        "nba_data = scrape_NBA_team_data([2017, 2018])"
      ],
      "metadata": {
        "id": "yZXw_9jWgr1w"
      },
      "execution_count": 8,
      "outputs": []
    }
  ]
}